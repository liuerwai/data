卡夫卡的一些概念：
	一个典型的Kafka集群中包含若干Produce，若干broker（一般broker数量越多，集群吞吐率越高），
	若干Consumer Group，以及一个Zookeeper集群。
	Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。
	Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。

	server:一个服务实列，又被称为broker
	Topic: 消息分类，一类消息，分成多个partition，消息追加到log文件尾部，消息在文件的位置称为offset。
	Producer：消息生产者，将消息发送给指定的Topic。也可以指定partition.
	Consumer: 消息消费者，每个consumer属于一个consumer group。发送到Toptic的消息只会被订阅的用户组中的一个用户消费。
卡夫卡中，消息被保存的时间由server的配置决定，不管消息有没有被消费，配置的时间到了，都会被删除。(log.retention.hours)
卡夫卡中，没有消息确认机制，无法保证可靠性。
用途：	1，jms
		2,webset activity tracking 
		3, log aggregation 
特性：
		1,持久性：使用文件系统存储。
		2，负载均衡：producer会和Topic下的所有partition leader保持Socket连接，producer决定发送到哪个partition上。
		
		

卡夫卡部署
    zookeeper 部署
		kafka集群是把状态保存在zookeeper中的，首先要搭建zookeeper集群。
		下载zookeeper,解压，在config/下找到 zoo_sample.cfg,这个是官方给我们的样板文件。
		重命名为zoo.cfg，zoo.cfg是官方指定的文件命名规则。
		zoo.cfg配置如下：
			tickTime=2000
			initLimit=10
			syncLimit=5
			dataDir=/opt/zookeeper/zkdata
			dataLogDir=/opt/zookeeper/zkdatalog
			clientPort=12181
			server.1=192.168.7.100:12888:13888
			server.2=192.168.7.101:12888:13888
			server.3=192.168.7.107:12888:13888
			#server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里
			#192.168.7.107为集群里的IP地址，第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行新的选举的端口默认是3888
		zoo.cfg配置解释如下：
			#tickTime：
			这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。
			#initLimit：
			这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒
			#syncLimit：
			这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是5*2000=10秒
			#dataDir：
			快照日志的存储路径
			#dataLogDir：
			事物日志的存储路径，如果不配置这个那么事物日志会默认存储到dataDir制定的目录，这样会严重影响zk的性能，当zk吞吐量较大的时候，产生的事物日志、快照日志太多
			#clientPort：
			这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。修改他的端口改大点
		创建myid文件
			在myid文件中设置serverid:echo "1" > /opt/zookeeper/zkdata/myid
			myid文件和server.myid  在快照目录下存放的标识本台服务器的文件，他是整个zk集群用来发现彼此的一个重要标识。
		启动服务
			./zkServer.sh start
		检查服务状态
			./zkServer.sh status
	kafka部署
		解压kafka，进入config下
		server.properties是主要的配置文件
		配置文件如下:
			broker.id=0  #当前机器在集群中的唯一标识，和zookeeper的myid性质一样
			port=19092 #当前kafka对外提供服务的端口默认是9092
			host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。
			num.network.threads=3 #这个是borker进行网络处理的线程数
			num.io.threads=8 #这个是borker进行I/O处理的线程数
			log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个
			socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
			socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
			socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小
			num.partitions=1 #默认的分区数，一个topic默认1个分区数
			log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
			message.max.byte=5242880  #消息保存的最大值5M
			default.replication.factor=2  #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
			replica.fetch.max.bytes=5242880  #取消息的最大直接数
			log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
			log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除
			log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能
			zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口
			
		
		
		
		
	
	

		
		
		
		
		
		
	
	